---
layout: post
title: Il bisogno di un'Intelligenza Artificiale "spiegabile"
bigimg: /img/web-3706562_1920.jpg
---

Forse in molti non se ne rendono ancora conto, ma **l'Intelligenza Artificiale sta cambiando ogni aspetto delle nostre vite**. La mattina, prima di uscire di casa, lasciamo decidere a Google Maps quale sia il tratto di strada migliore da percorrere per arrivare in tempo a scuola, all'università oppure a lavoro. Ci fidiamo del nostro smartphone come di nessun altro: gli lasciamo decidere le cose da comprare, le canzoni da ascoltare, i film da guardare. D'altronde, lui conosce i nostri gusti come nessun altro, e ce lo dimostra tramite delle pubblicità mirate che ci invitano ad acquistare prodotti di cui abbiamo appena parlato coi nostri amici e che probabilmente acquisteremo pur non avendone effettivamente bisogno. 

Allo stato attuale, non bisogna pensare ai sistemi di AI come se fossero degli umanoidi con una vera e propria intelligenza e coscienza di sé --- come Ava in *Ex Machina*, famoso film del 2015 scritto e diretto da Alex Garland ---, in quanto si tratta per lo più di **sistemi software** che, addestrati per un unico task, **applicano varie formule matematiche per prendere delle decisioni sulla base dei dati che gli vengono forniti**. 

Nella maggior parte dei casi, tali sistemi sono tanto complessi da non permettere all'utilizzatore (nemmeno al loro stesso creatore!) di capire quale sia stato il processo "cognitivo" che ha portato a una particolare decisione. Essi sono, dunque, come delle **enormi scatole nere** (in gergo, *black-box*) che trasformano in decisioni ciò che mettiamo al loro interno ma che non ci lasciano intravedere ciò che nascondono. Voi vi fidereste? No? Eppure non vedete l'ora di mettere piede su un'auto a guida autonoma. 
<p align= 'center'>
<img src="/img/img20200126_12021114.png" alt="blackbox" style="width:400px;"/>
</p>

Un [articolo su New Scientist](https://www.newscientist.com/article/2222907-ai-can-predict-if-youll-die-soon-but-weve-no-idea-how-it-works/) sottolinea le enormi potenzialità dell'Intelligenza Artificiale: un algoritmo è in grado di ottenere prestazioni migliori rispetto ad esperti medici nella rilevazione di pazienti ad alto rischio sulla base dei loro elettrocardiogrammi (ECG) **riuscendo, in qualche modo, a carpire dai dati qualcosa che all'umano sfugge**. Tuttavia, l'applicabilità di questi sistemi è ancor'oggi ostacolata dalla loro "opacità": un medico, per esempio, nel fornire una diagnosi, non si affiderà mai all'aiuto di una macchina se essa non associa al suo consiglio una spiegazione scientificamente accettabile.

Da quando eravamo dei bambini cerchiamo di capire come funziona il mondo riempiendo di domande i nostri genitori, gli insegnanti e noi stessi. Lo abbiamo fatto per capire perché si debba oltrepassare la carreggiata camminando sulle strisce pedonali, perché studiare la lingua latina sia utile nella vita, perché l'ultima nostra relazione di coppia sia finita male. A seguito di un compito in classe o di un'esame andato male, le opzioni sono solitamente due: dare la colpa al professore oppure cercare di capire quale sia stato il processo cognitivo che lo ha portato a darci quel voto. Nel secondo caso, ci diamo la possibilità di migliorare. Può sembrare strano, ma **se le macchine**, che stanno diventando sempre più intelligenti e performanti, **potessero darci delle spiegazioni, ci permetterebbero di imparare e migliorare**.

La necessità di un'AI spiegabile non nasce solo da questo, ma anche e soprattutto dal principio di *responsabilità* delle azioni: se, per esempio, un'auto a guida autonoma, senza un conducente al suo interno, investisse un pedone ([ed è successo!](https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe)), a chi verrebbe inputata la colpa? È per tale motivo che **i governi in tutto il mondo stanno cominciando a regolare l'utilizzo dell'Intelligenza Artificiale, affinché le applicazioni rispettino determinati principi, tra i quali l'interpretabilità delle decisioni**. A titolo esemplificativo, di seguito è riportatata parte dell'[articolo 22](https://www.cyberlaws.it/2017/articolo-22-gdpr-regolamento-generale-sulla-protezione-dei-dati-ue2016679/) del GDPR (*General Data Protection Regulation*):

> L’interessato ha il diritto di non essere sottoposto a una decisione basata unicamente sul trattamento automatizzato, compresa la profilazione, che produca effetti giuridici che lo riguardano o che incida in modo analogo significativamente sulla sua persona.

Nel momento in cui un algoritmo, incrociando i nostri dati, deciderà che non possiamo ricevere un prestito bancario o non possiamo inserire il nostro CV per candidarci per una posizione lavorativa, sarà nostro diritto chiedere: "*perché?*

---------------------------------------------
